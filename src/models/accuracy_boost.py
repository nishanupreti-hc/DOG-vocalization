import torch
import torch.nn as nn
import numpy as np
from sklearn.calibration import CalibratedClassifierCV
from sklearn.ensemble import VotingClassifier
import librosa
from typing import Dict, List, Tuple

class MultiScaleFeatureExtractor(nn.Module):
    """Extract features at multiple time scales for better accuracy"""
    
    def __init__(self):
        super().__init__()
        # Multi-scale convolutions
        self.conv_1ms = nn.Conv1d(1, 64, kernel_size=16, stride=8)  # 1ms scale
        self.conv_10ms = nn.Conv1d(1, 64, kernel_size=160, stride=80)  # 10ms scale
        self.conv_100ms = nn.Conv1d(1, 64, kernel_size=1600, stride=800)  # 100ms scale
        
        self.pool = nn.AdaptiveAvgPool1d(100)
        self.fusion = nn.Linear(192, 256)
    
    def forward(self, x):
        # x shape: (batch, 1, samples)
        feat_1ms = torch.relu(self.conv_1ms(x))
        feat_10ms = torch.relu(self.conv_10ms(x))
        feat_100ms = torch.relu(self.conv_100ms(x))
        
        # Pool to same length
        feat_1ms = self.pool(feat_1ms)
        feat_10ms = self.pool(feat_10ms)
        feat_100ms = self.pool(feat_100ms)
        
        # Concatenate and fuse
        combined = torch.cat([feat_1ms, feat_10ms, feat_100ms], dim=1)
        fused = self.fusion(combined.mean(dim=2))
        
        return fused

class AttentionMechanism(nn.Module):
    """Attention mechanism for focusing on important audio segments"""
    
    def __init__(self, feature_dim=256):
        super().__init__()
        self.attention = nn.Sequential(
            nn.Linear(feature_dim, 128),
            nn.Tanh(),
            nn.Linear(128, 1)
        )
    
    def forward(self, x):
        # x shape: (batch, seq_len, features)
        attention_weights = torch.softmax(self.attention(x), dim=1)
        attended = torch.sum(x * attention_weights, dim=1)
        return attended, attention_weights

class HighAccuracyDogModel(nn.Module):
    """High-accuracy model with multiple improvements"""
    
    def __init__(self, num_classes_tier1=12, num_classes_tier2=16):
        super().__init__()
        
        # Multi-scale feature extraction
        self.feature_extractor = MultiScaleFeatureExtractor()
        
        # Attention mechanism
        self.attention = AttentionMechanism(256)
        
        # Contextual features
        self.context_encoder = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64)
        )
        
        # Multi-task heads with uncertainty
        self.tier1_head = nn.Sequential(
            nn.Linear(320, 256),  # 256 + 64 context
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes_tier1)
        )
        
        self.tier2_head = nn.Sequential(
            nn.Linear(320, 256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes_tier2)
        )
        
        # Uncertainty estimation
        self.uncertainty_head = nn.Sequential(
            nn.Linear(320, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    
    def forward(self, audio_features, context_features=None):
        # Extract multi-scale features
        features = self.feature_extractor(audio_features)
        
        # Add sequence dimension for attention
        features_seq = features.unsqueeze(1).repeat(1, 10, 1)  # Simulate sequence
        attended_features, attention_weights = self.attention(features_seq)
        
        # Context encoding
        if context_features is not None:
            context_encoded = self.context_encoder(context_features)
        else:
            context_encoded = torch.zeros(attended_features.size(0), 64).to(attended_features.device)
        
        # Combine features
        combined_features = torch.cat([attended_features, context_encoded], dim=1)
        
        # Predictions
        tier1_logits = self.tier1_head(combined_features)
        tier2_logits = self.tier2_head(combined_features)
        uncertainty = self.uncertainty_head(combined_features)
        
        return {
            'tier1_logits': tier1_logits,
            'tier2_logits': tier2_logits,
            'uncertainty': uncertainty,
            'attention_weights': attention_weights
        }

class EnsemblePredictor:
    """Ensemble of multiple models for higher accuracy"""
    
    def __init__(self):
        self.models = []
        self.weights = []
    
    def add_model(self, model, weight=1.0):
        """Add model to ensemble"""
        self.models.append(model)
        self.weights.append(weight)
    
    def predict(self, x, context=None):
        """Ensemble prediction"""
        predictions = []
        uncertainties = []
        
        for model, weight in zip(self.models, self.weights):
            model.eval()
            with torch.no_grad():
                output = model(x, context)
                
                # Weight predictions
                tier1_probs = torch.softmax(output['tier1_logits'], dim=1) * weight
                tier2_probs = torch.sigmoid(output['tier2_logits']) * weight
                
                predictions.append({
                    'tier1_probs': tier1_probs,
                    'tier2_probs': tier2_probs
                })
                uncertainties.append(output['uncertainty'])
        
        # Combine predictions
        combined_tier1 = torch.stack([p['tier1_probs'] for p in predictions]).mean(dim=0)
        combined_tier2 = torch.stack([p['tier2_probs'] for p in predictions]).mean(dim=0)
        combined_uncertainty = torch.stack(uncertainties).mean(dim=0)
        
        return {
            'tier1_probs': combined_tier1,
            'tier2_probs': combined_tier2,
            'uncertainty': combined_uncertainty
        }

class ActiveLearningSelector:
    """Select most informative samples for labeling"""
    
    def __init__(self, model):
        self.model = model
    
    def select_uncertain_samples(self, audio_batch, n_samples=10):
        """Select samples with highest uncertainty"""
        self.model.eval()
        uncertainties = []
        
        with torch.no_grad():
            for audio in audio_batch:
                output = self.model(audio.unsqueeze(0))
                uncertainty = output['uncertainty'].item()
                uncertainties.append(uncertainty)
        
        # Select top uncertain samples
        uncertain_indices = np.argsort(uncertainties)[-n_samples:]
        return uncertain_indices
    
    def select_diverse_samples(self, features_batch, n_samples=10):
        """Select diverse samples using clustering"""
        from sklearn.cluster import KMeans
        
        # Flatten features
        features_flat = features_batch.view(features_batch.size(0), -1).numpy()
        
        # Cluster and select representatives
        kmeans = KMeans(n_clusters=n_samples, random_state=42)
        clusters = kmeans.fit_predict(features_flat)
        
        # Select one sample per cluster (closest to centroid)
        selected_indices = []
        for i in range(n_samples):
            cluster_mask = clusters == i
            if cluster_mask.any():
                cluster_features = features_flat[cluster_mask]
                centroid = kmeans.cluster_centers_[i]
                
                # Find closest to centroid
                distances = np.linalg.norm(cluster_features - centroid, axis=1)
                closest_idx = np.where(cluster_mask)[0][np.argmin(distances)]
                selected_indices.append(closest_idx)
        
        return selected_indices

class CalibrationImprover:
    """Improve prediction calibration for better confidence estimates"""
    
    def __init__(self):
        self.calibrator = None
    
    def fit_calibration(self, predictions, true_labels):
        """Fit calibration on validation set"""
        # Convert predictions to confidence scores
        confidences = np.max(predictions, axis=1)
        correct = (np.argmax(predictions, axis=1) == true_labels).astype(int)
        
        # Fit isotonic regression for calibration
        from sklearn.isotonic import IsotonicRegression
        self.calibrator = IsotonicRegression(out_of_bounds='clip')
        self.calibrator.fit(confidences, correct)
    
    def calibrate_confidence(self, predictions):
        """Apply calibration to predictions"""
        if self.calibrator is None:
            return predictions
        
        confidences = np.max(predictions, axis=1)
        calibrated_confidences = self.calibrator.predict(confidences)
        
        # Scale predictions to match calibrated confidence
        scaling_factors = calibrated_confidences / confidences
        calibrated_predictions = predictions * scaling_factors.reshape(-1, 1)
        
        return calibrated_predictions

class AccuracyBooster:
    """Main class for boosting model accuracy"""
    
    def __init__(self):
        self.ensemble = EnsemblePredictor()
        self.calibrator = CalibrationImprover()
        self.active_learner = None
    
    def create_ensemble(self, base_models):
        """Create ensemble from multiple trained models"""
        # Add models with different weights based on validation performance
        for i, model in enumerate(base_models):
            weight = 1.0 / (i + 1)  # Decreasing weights
            self.ensemble.add_model(model, weight)
    
    def improve_with_pseudolabeling(self, unlabeled_data, confidence_threshold=0.9):
        """Use high-confidence predictions as pseudo-labels"""
        pseudo_labels = []
        pseudo_data = []
        
        for data in unlabeled_data:
            prediction = self.ensemble.predict(data)
            
            # Use high-confidence predictions
            tier1_confidence = torch.max(prediction['tier1_probs']).item()
            if tier1_confidence > confidence_threshold:
                pseudo_label = torch.argmax(prediction['tier1_probs']).item()
                pseudo_labels.append(pseudo_label)
                pseudo_data.append(data)
        
        return pseudo_data, pseudo_labels
    
    def test_time_augmentation(self, audio, n_augmentations=5):
        """Apply test-time augmentation for better predictions"""
        predictions = []
        
        for _ in range(n_augmentations):
            # Apply random augmentation
            augmented_audio = self._augment_audio(audio)
            
            # Get prediction
            pred = self.ensemble.predict(augmented_audio)
            predictions.append(pred)
        
        # Average predictions
        avg_tier1 = torch.stack([p['tier1_probs'] for p in predictions]).mean(dim=0)
        avg_tier2 = torch.stack([p['tier2_probs'] for p in predictions]).mean(dim=0)
        
        return {
            'tier1_probs': avg_tier1,
            'tier2_probs': avg_tier2
        }
    
    def _augment_audio(self, audio):
        """Apply random augmentation to audio"""
        # Convert to numpy if tensor
        if isinstance(audio, torch.Tensor):
            audio_np = audio.cpu().numpy()
        else:
            audio_np = audio
        
        # Random augmentations
        aug_type = np.random.choice(['pitch', 'time', 'noise'])
        
        if aug_type == 'pitch':
            # Pitch shift
            n_steps = np.random.uniform(-1, 1)
            audio_np = librosa.effects.pitch_shift(audio_np, sr=16000, n_steps=n_steps)
        elif aug_type == 'time':
            # Time stretch
            rate = np.random.uniform(0.95, 1.05)
            audio_np = librosa.effects.time_stretch(audio_np, rate=rate)
        else:
            # Add noise
            noise = np.random.randn(*audio_np.shape) * 0.01
            audio_np = audio_np + noise
        
        return torch.from_numpy(audio_np).float()

def create_high_accuracy_system():
    """Create complete high-accuracy system"""
    
    print("ðŸŽ¯ Creating High-Accuracy DogSpeak System")
    print("=" * 45)
    
    # Create high-accuracy model
    model = HighAccuracyDogModel()
    
    # Create ensemble
    ensemble = EnsemblePredictor()
    ensemble.add_model(model, weight=1.0)
    
    # Create accuracy booster
    booster = AccuracyBooster()
    booster.ensemble = ensemble
    
    # Test with dummy data
    dummy_audio = torch.randn(1, 1, 64000)  # 4 seconds at 16kHz
    
    prediction = booster.test_time_augmentation(dummy_audio)
    
    print("âœ… High-accuracy model created")
    print(f"âœ… Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    print("âœ… Ensemble prediction ready")
    print("âœ… Test-time augmentation enabled")
    print("âœ… Calibration system ready")
    
    return booster, model

if __name__ == "__main__":
    create_high_accuracy_system()
